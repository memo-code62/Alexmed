import streamlit as st
import os
import io
from pathlib import Path
from PIL import Image

# Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ LlamaIndex
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage
from llama_index.readers.web import SimpleWebPageReader
from llama_index.embeddings.gemini import GeminiEmbedding
# Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Gemini (ØªÙ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† GeminiMultiModal)
from llama_index.llms.gemini import Gemini

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø­Ø²Ù…Ø© Ø¬ÙˆØ¬Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±
from google import genai 

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªÙ†Ø²ÙŠÙ„
from docx import Document
from pptx import Presentation
from pptx.util import Inches 

# ---------------------------------
# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ø«ÙˆØ§Ø¨Øª
# ---------------------------------

# **Ù‡Ø§Ù…:** Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ ÙÙŠ Secrets (GEMINI_API_KEY) 
INDEX_STORAGE_DIR = "storage"
PDF_DIR = "./" 
IMAGE_GENERATION_MODEL = 'imagen-3.0-generate-002' 

MEDICAL_URLS = [
    "https://pubmed.ncbi.nlm.nih.gov/", 
    "https://www.who.int/ar", 
    "https://www.cdc.gov/",
    "https://www.mayoclinic.org/",
    "https://www.medscape.com/",
    "https://www.hopkinsmedicine.org/",
]

SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø·Ù„Ø§Ø¨ Ø§Ù„Ø·Ø¨. "
    "ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø© (Ø¥Ù† ÙˆØ¬Ø¯Øª) ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©. "
    "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ **Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ØŒ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŒ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªØ´Ø±ÙŠØ­ÙŠØ©)** Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©/Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø£Ù‚ÙˆØ§Ø³. "
    "ÙŠØ¬Ø¨ Ø£Ù† ØªÙ‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ ÙÙŠ Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù…ØŒ ÙˆØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø±Ù‚Ù…Ø© Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª. ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙˆØªÙ„Ø®ÙŠØµØ§Øª Ùˆ Mnemonic Devices (ØªØ­Ø´ÙŠØ´Ø§Øª) Ø¹Ù†Ø¯ Ø·Ù„Ø¨Ù‡Ø§."
)
# ---------------------------------
# 2. Ø¨Ù†Ø§Ø¡/ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("âŒ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ù„Ù€ Gemini Ù…ÙÙ‚ÙˆØ¯! ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØªÙ‡ ÙÙŠ Secrets.")
        return None

    try:
        # 1. ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© (LLMs)
        llm_multi = Gemini(model="gemini-2.5-flash")
        llm_text = Gemini(model="gemini-2.5-flash")
        
        # 2. ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† (Embedding Model) Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© OpenAI
        embed_model = GeminiEmbedding(model_name="text-embedding-004") 
        
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini: {e}")
        return None

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm_text)
        
    else:
        st.warning("â³ Ø¬Ø§Ø±ÙŠ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹)...")
        
        try:
            # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© (ØªÙ… Ø­Ø°Ù Ø§Ù„ÙˆØ³ÙŠØ·Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©)
            pdf_documents = SimpleDirectoryReader(
                input_dir=PDF_DIR, 
                required_exts=[".pdf", ".jpg", ".png"]
            ).load_data()
            
            # 2. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© (ØªÙ… Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚)
            url_documents = SimpleWebPageReader().load_data(urls=MEDICAL_URLS)
            
            documents = pdf_documents + url_documents
            st.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(documents)} Ù…Ø³ØªÙ†Ø¯ (Ù†ØµÙŠ ÙˆØ¨ØµØ±ÙŠ). Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙÙ‡Ø±Ø³Ø©...")

            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm_multi,
                embed_model=embed_model, # ØªÙ…Ø±ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Gemini
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ­ÙØ¸Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø§Ù‡Ø².")
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø­Ø±Ø¬ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³: {e}")
            return None

    query_engine = index.as_query_engine(
        llm=llm_text,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine
    
# ---------------------------------
# 3. Ø¯ÙˆØ§Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· ÙˆØ§Ù„ØªÙ†Ø²ÙŠÙ„
# ---------------------------------

@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """ØªØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ Imagen Ù„Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø«Ø§Ø¨ØªØ© (Ø¬Ø±Ø§ÙÙŠÙƒ) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ."""
    client = get_gemini_client()

    full_prompt = (
        f"Detailed medical diagram, high-quality colorful graphic design, "
        f"featuring arrows and explanatory labels showing the {prompt}"
    )

    st.info(f"ğŸ¨ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø¬Ø±Ø§ÙÙŠÙƒ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù€: {prompt}")

    try:
        if is_animation:
            st.warning("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ/Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© Ù…Ø¹Ù‚Ø¯ ÙÙŠ Streamlit. Ø³ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø«Ø§Ø¨ØªØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.")

        result = client.models.generate_images(
            model=IMAGE_GENERATION_MODEL,
            prompt=full_prompt,
            config=dict(
                number_of_images=1,
                output_mime_type="image/jpeg",
                aspect_ratio="16:9"
            )
        )

        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ."

    except Exception as e:
        if "API_KEY_INVALID" in str(e):
            return None, "Ø®Ø·Ø£: Ù…ÙØªØ§Ø­ Gemini API ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ ØºÙŠØ± Ù…Ù‡ÙŠØ£ Ù„Ø®Ø¯Ù…Ø© Imagen."
        return None, f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©: {e}"

def convert_text_to_docx(text_content):
    """ØªØ­ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù„Ù Word (DOCX)."""
    document = Document()
    document.add_paragraph(text_content)
    buffer = io.BytesIO()
    document.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()

def convert_text_to_pptx(text_content):
    """ØªØ­ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ (PPTX) Ø¨ØªÙ‚Ø³ÙŠÙ… Ø¨Ø³ÙŠØ·."""
    prs = Presentation()
    slide_layout = prs.slide_layouts[1] 

    paragraphs = text_content.split('\n\n') 

    for i, p in enumerate(paragraphs):
        if not p.strip(): continue

        slide = prs.slides.add_slide(slide_layout)
        title = slide.shapes.title
        title.text = f"Ø´Ø±ÙŠØ­Ø© {i+1}: " + p.split('\n')[0][:50] + "..."

        body = slide.placeholders[1]
        tf = body.text_frame
        tf.text = p

    buffer = io.BytesIO()
    prs.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()

def handle_image_generation(content, is_animation=False):
    """ÙˆØ¸ÙŠÙØ© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¹Ø±Ø¶Ù‡Ø§."""
    image_prompt = content[:200]
    image_bytes, error = generate_image(image_prompt, is_animation=is_animation)

    if image_bytes:
        st.image(image_bytes, caption=f"ØµÙˆØ±Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ù„Ù€: {image_prompt}...")

        st.download_button(
            label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙƒÙ€ JPG",
            data=image_bytes,
            file_name="medical_graphic.jpg",
            mime="image/jpeg",
            key=f"download_img_{hash(content)}"
        )
    else:
        st.error(f"ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {error}")

# ---------------------------------
# 4. ÙˆØ§Ø¬Ù‡Ø© Streamlit (Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)
# ---------------------------------

st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø·Ø¨ÙŠ (RAG+Vision)", layout="wide")
st.title("ğŸ‘ï¸ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø¨ØµØ±ÙŠ (RAG+Vision)")
st.caption("ÙŠØ­Ù„Ù„ Ù…Ù„ÙØ§ØªÙƒ ÙˆØµÙˆØ±Ùƒ Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ ÙˆÙŠØ¯Ø¹Ù… Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯.")

query_engine = setup_rag_engine()

if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ù„ØªÙ†Ø²ÙŠÙ„ Ù„Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
            if message["role"] == "assistant":
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    if st.button("ğŸ–¼ï¸ ØªÙˆÙ„ÙŠØ¯ Ø¬Ø±Ø§ÙÙŠÙƒ", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                with col2:
                    docx_file = convert_text_to_docx(message["content"])
                    st.download_button(
                        label="ğŸ“„ ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ Word",
                        data=docx_file,
                        file_name="summary.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key=f"download_docx_{hash(message['content'])}" 
                    )

                with col3:
                    pptx_file = convert_text_to_pptx(message["content"])
                    st.download_button(
                        label="ğŸ“Š ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ PPTX",
                        data=pptx_file,
                        file_name="presentation.pptx",
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        key=f"download_pptx_{hash(message['content'])}" 
                    )

                with col4:
                    st.download_button(
                        label="ğŸ“œ ØªÙ†Ø²ÙŠÙ„ ÙƒÙ€ TXT",
                        data=message["content"],
                        file_name="summary.txt",
                        mime="text/plain",
                        key=f"download_txt_{hash(message['content'])}" 
                    )

    # >>> Ù…Ù†Ø·Ù‚Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ø³Ø¤Ø§Ù„
    uploaded_file = st.file_uploader("ğŸ–¼ï¸ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ© Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù†Ù‡Ø§ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type=["png", "jpg", "jpeg"])

    if prompt := st.chat_input("Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø·Ø¨ÙŠØ§Ù‹ØŒ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø±ÙØ§Ù‚ ØµÙˆØ±Ø©..."):

        user_message = {"role": "user", "content": prompt}
        text_and_image_input = prompt
        image_to_query = None

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", width=200)

            image_to_query = [image] 
            text_and_image_input = f"Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ù…Ø¹ØªÙ…Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ÙƒØŒ Ø«Ù… Ø£Ø¬Ø¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„: {prompt}"

        st.session_state.messages.append(user_message)
        with st.chat_message("user"):
            st.markdown(text_and_image_input)

        with st.chat_message("assistant"):
            response = query_engine.query(text_and_image_input, images=image_to_query) 

            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})