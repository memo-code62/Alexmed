import streamlit as st
import os
import io
from pathlib import Path

# ุงูุงุณุชูุฑุงุฏุงุช ุงูุฃุณุงุณูุฉ ูู LlamaIndex
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage
from llama_index.readers.web import SimpleWebPageReader

# ุงุณุชูุฑุงุฏุงุช Multi-modal RAG ู Gemini
from llama_index.multi_modal_llms.google import GeminiMultiModal

from llama_index.google.genai import Gemini 
from PIL import Image

# ุงุณุชูุฑุงุฏ ุญุฒูุฉ ุฌูุฌู ูุชูููุฏ ุงูุตูุฑ
from google import genai 

# ุงุณุชูุฑุงุฏ ููุชุจุงุช ุงูุชูุฒูู
from docx import Document
from pptx import Presentation
from pptx.util import Inches 

# ---------------------------------
# 1. ุงูุฅุนุฏุงุฏุงุช ุงูุฃุณุงุณูุฉ
# ---------------------------------

# **ูุงู:** ุถุน ููุชุงุญู ูู Secrets (GEMINI_API_KEY)
# os.environ["GEMINI_API_KEY"] = "ุฃุฏุฎู_ููุชุงุญ_API_ุงูุฎุงุต_ุจู_ููุง" 

INDEX_STORAGE_DIR = "storage"
PDF_DIR = "./" 
IMAGE_GENERATION_MODEL = 'imagen-3.0-generate-002' 

MEDICAL_URLS = [
    "https://pubmed.ncbi.nlm.nih.gov/", 
    "https://www.who.int/ar", 
    "https://www.cdc.gov/",
    "https://www.mayoclinic.org/",
    "https://www.medscape.com/",
    "https://www.hopkinsmedicine.org/",
]

SYSTEM_PROMPT = (
    "ุฃูุช ูุณุงุนุฏ ุทุจู ุฐูู ูุชุฎุตุต ูู ุงูุฅุฌุงุจุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุทูุงุจ ุงูุทุจ. "
    "ูุฌุจ ุนููู ุชุญููู ุงููุต ูุงูุตูุฑุฉ ุงููุฑููุฉ (ุฅู ูุฌุฏุช) ูุงุณุชุฎุฏุงููุง ูุน ุงููุฑุงุฌุน ุงููุณุชุฑุฌุนุฉ ููุฅุฌุงุจุฉ. "
    "ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉุ ูุน ุงูุญูุงุธ ุนูู ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุงูุฃุณุงุณูุฉ (ุงูุฃูุฑุงุถุ ุงูุฃุฏููุฉุ ุงููุตุทูุญุงุช ุงูุชุดุฑูุญูุฉ) ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ ุฏุงุฎู ุงูุฃููุงุณ. "
    "ุนูุฏ ุทูุจ ุงูุฌุฏุงูู ุฃู ุงูููุงุฑูุงุช ุฃู ุงูุดุฑูุญุงุช ุงููุนูุฏุฉุ ูุฌุจ ุฃู ุชููุธููู ุงูุฅุฌุงุจุฉ ูู ุดูู ูุต ูููููู (Markdown) ูุงุถุญ ูููุฌุฒ. "
    "ูู ุจุฅูุดุงุก ุฃุณุฆูุฉ ุชุฏุฑูุจูุฉ ูุชูุฎูุตุงุช ู Mnemonic Devices (ุชุญุดูุดุงุช) ุนูุฏ ุทูุจูุง."
)

# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ ุงููุชุนุฏุฏ ุงูุฃููุงุท
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets.")
        return None

    try:
        llm_multi = GeminiMultiModal(model="gemini-2.5-flash")
        llm_text = Gemini(model="gemini-2.5-flash")
    except Exception as e:
        st.error(f"โ ูุดู ุชููุฆุฉ ูููุฐุฌ Gemini: {e}")
        return None

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm_text)
        
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท (ูุฏ ูุณุชุบุฑู ููุชูุง ุทูููุงู)...")
        
        try:
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf", ".jpg", ".png"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ (ูุตู ูุจุตุฑู). ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm_multi,
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ูุญูุธูุง ุจูุฌุงุญ!")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    query_engine = index.as_query_engine(
        llm=llm_text,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ุฏูุงู ุชูููุฏ ุงููุณุงุฆุท ูุงูุชูุฒูู
# ---------------------------------

@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """ุชุณุชุฎุฏู ูููุฐุฌ Imagen ูุฅูุดุงุก ุตูุฑุฉ ุซุงุจุชุฉ (ุฌุฑุงููู) ุจูุงุกู ุนูู ุงููุตู."""
    client = get_gemini_client()
    
    full_prompt = (
        f"Detailed medical diagram, high-quality colorful graphic design, "
        f"featuring arrows and explanatory labels showing the {prompt}"
    )
    
    st.info(f"๐จ ุฌุงุฑู ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู ูู: {prompt}")

    try:
        if is_animation:
            st.warning("ุชูููุฏ ุงูููุฏูู/ุงูุตูุฑ ุงููุชุญุฑูุฉ ูุนูุฏ ูู Streamlit. ุณูุชู ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ ุจุฏูุงู ูู ุฐูู.")
            
        result = client.models.generate_images(
            model=IMAGE_GENERATION_MODEL,
            prompt=full_prompt,
            config=dict(
                number_of_images=1,
                output_mime_type="image/jpeg",
                aspect_ratio="16:9"
            )
        )
        
        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "ูู ูุชููู ุงููููุฐุฌ ูู ุชูููุฏ ุตูุฑุฉ ุจูุงุกู ุนูู ุงููุตู."

    except Exception as e:
        return None, f"ุฎุทุฃ ูู ุชูููุฏ ุงูุตูุฑุฉ: {e}"

def convert_text_to_docx(text_content):
    """ุชุญูู ุงููุต ุฅูู ููู Word (DOCX)."""
    document = Document()
    document.add_paragraph(text_content)
    buffer = io.BytesIO()
    document.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()

def convert_text_to_pptx(text_content):
    """ุชุญูู ุงููุต ุฅูู ุนุฑุถ ุชูุฏููู (PPTX) ุจุชูุณูู ุจุณูุท."""
    prs = Presentation()
    
    # ุชูุณูู ุงููุต ุฅูู ุดุฑุงุฆุญ (ุจุงูุชุฑุงุถ ุฃู ูู ุณุทุฑูู ููุซูุงู ุดุฑูุญุฉ ุฌุฏูุฏุฉ)
    paragraphs = text_content.split('\n\n') 
    
    for i, p in enumerate(paragraphs):
        if not p.strip(): continue # ุชุฎุทู ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ
            
        # ุงุณุชุฎุฏุงู ุชุฎุทูุท ุงูุนููุงู ูุงููุญุชูู
        slide_layout = prs.slide_layouts[1] 
        slide = prs.slides.add_slide(slide_layout)
        
        # ุงูุนููุงู ูู ุฃูู 50 ุญุฑููุง
        title = slide.shapes.title
        title.text = f"ุดุฑูุญุฉ {i+1}: " + p.split('\n')[0][:50] + "..."
        
        # ุงููุญุชูู ูู ุจุงูู ุงููุต
        body = slide.placeholders[1]
        tf = body.text_frame
        tf.text = p

    buffer = io.BytesIO()
    prs.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()


# ---------------------------------
# 4. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู (RAG+Vision)", layout="wide")
st.title("๐๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุจุตุฑู (RAG+Vision)")
st.caption("ูุญูู ูููุงุชู ูุตูุฑู ุงููุฑููุนุฉ ููุฅุฌุงุจุฉุ ููุฏุนู ุงูุชูุฒูู ุงููุชุนุฏุฏ.")

query_engine = setup_rag_engine()

def handle_image_generation(content, is_animation=False):
    image_prompt = content[:200]
    image_bytes, error = generate_image(image_prompt, is_animation=is_animation)

    if image_bytes:
        st.image(image_bytes, caption=f"ุตูุฑุฉ ุชูุถูุญูุฉ ุชู ุชูููุฏูุง ูู: {image_prompt}...")
        
        st.download_button(
            label="โฌ๏ธ ุชูุฒูู ุงูุตูุฑุฉ ูู JPG",
            data=image_bytes,
            file_name="medical_graphic.jpg",
            mime="image/jpeg",
            key=f"download_img_{hash(content)}"
        )
    else:
        st.error(f"ูุดู ุงูุชูููุฏ: {error}")


if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ุนุฑุถ ุงูุฑุณุงุฆู ุงูุณุงุจูุฉ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ุฃุฒุฑุงุฑ ุงูุชูููุฏ ูุงูุชูุฒูู ูุฑุฏ ุงููุณุงุนุฏ
            if message["role"] == "assistant":
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    if st.button("๐ผ๏ธ ุชูููุฏ ุฌุฑุงููู", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                with col2:
                    docx_file = convert_text_to_docx(message["content"])
                    st.download_button(
                        label="๐ ุชูุฒูู ูู Word",
                        data=docx_file,
                        file_name="summary.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key=f"download_docx_{hash(message['content'])}" 
                    )
                    
                with col3:
                    pptx_file = convert_text_to_pptx(message["content"])
                    st.download_button(
                        label="๐ ุชูุฒูู ูู PPTX",
                        data=pptx_file,
                        file_name="presentation.pptx",
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        key=f"download_pptx_{hash(message['content'])}" 
                    )
                
                with col4:
                    st.download_button(
                        label="๐ ุชูุฒูู ูู TXT",
                        data=message["content"],
                        file_name="summary.txt",
                        mime="text/plain",
                        key=f"download_txt_{hash(message['content'])}" 
                    )

    # >>> ููุทูุฉ ุชุญููู ุงูุตูุฑุฉ ูุงูุณุคุงู
    uploaded_file = st.file_uploader("๐ผ๏ธ ุงุฑูุน ุตูุฑุฉ ุทุจูุฉ ููุณุคุงู ุนููุง (ุงุฎุชูุงุฑู)", type=["png", "jpg", "jpeg"])

    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงูุ ูููููู ุฅุฑูุงู ุตูุฑุฉ..."):
        
        user_message = {"role": "user", "content": prompt}
        text_and_image_input = prompt
        image_to_query = None

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ุงูุตูุฑุฉ ุงููุฑููุนุฉ", width=200)
            
            image_to_query = [image] 
            text_and_image_input = f"ุญูู ุงูุตูุฑุฉ ุงููุฑููุนุฉ ูุนุชูุฏุงู ุนูู ูุฑุงุฌุนูุ ุซู ุฃุฌุจ ุนู ุงูุณุคุงู: {prompt}"

        st.session_state.messages.append(user_message)
        with st.chat_message("user"):
            st.markdown(text_and_image_input)

        with st.chat_message("assistant"):
            response = query_engine.query(text_and_image_input, images=image_to_query) 
            
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})
    "ุนูุฏ ุทูุจ ุงูุฌุฏุงูู ุฃู ุงูููุงุฑูุงุช ุฃู ุงูุดุฑูุญุงุช ุงููุนูุฏุฉุ ูุฌุจ ุฃู ุชููุธููู ุงูุฅุฌุงุจุฉ ูู ุดูู ูุต ูููููู (Markdown) ูุงุถุญ ูููุฌุฒ."
# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ ุงููุชุนุฏุฏ ุงูุฃููุงุท
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets.")
        return None

    try:
        # LLM Multi-modal ููุฑุงุกุฉ ูููู ุงููุตูุต ูุงูุตูุฑ ูู ุงูููุฑุณ
        llm_multi = GeminiMultiModal(model="gemini-2.5-flash")
        # LLM ุงููุตู ููุญุฑู ุงูุงุณุชุนูุงู ุงูููุงุฆู
        llm_text = Gemini(model="gemini-2.5-flash")
        
    except Exception as e:
        st.error(f"โ ูุดู ุชููุฆุฉ ูููุฐุฌ Gemini: {e}")
        return None

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm_text)
        
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท (ุชุฃูุฏ ูู ูุฌูุฏ ุตูุฑ JPG/PNG ููููุงุช PDF)...")
        
        try:
            # ุงูุขู ุชูุฑุฃ ุงููุตูุต ูู PDF ูุงูุตูุฑ ูู JPG/PNG
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf", ".jpg", ".png"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ (ูุตู ูุจุตุฑู). ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm_multi, # ุงุณุชุฎุฏุงู ูููุฐุฌ ุงูุฃููุงุท ุงููุชุนุฏุฏุฉ ููููุฑุณุฉ
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ูุญูุธูุง ุจูุฌุงุญ!")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    query_engine = index.as_query_engine(
        llm=llm_text,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ุฏูุงู ุชูููุฏ ุงููุณุงุฆุท
# ---------------------------------

@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """
    ุชุณุชุฎุฏู ูููุฐุฌ Imagen ูุฅูุดุงุก ุตูุฑุฉ ุซุงุจุชุฉ (ุฌุฑุงููู) ุจูุงุกู ุนูู ุงููุตู.
    """
    client = get_gemini_client()
    
    # ุชุญุณูู ุงููุทุงูุจุฉ ูุฅูุดุงุก ุตูุฑุฉ ุทุจูุฉ ุงุญุชุฑุงููุฉ
    full_prompt = (
        f"Detailed medical diagram, high-quality colorful graphic design, "
        f"featuring arrows and explanatory labels showing the {prompt}"
    )
    
    st.info(f"๐จ ุฌุงุฑู ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู ูู: {prompt}")

    try:
        if is_animation:
            st.warning("ุชูููุฏ ุงูููุฏูู/ุงูุตูุฑ ุงููุชุญุฑูุฉ ูุนูุฏ ูู Streamlit. ุณูุชู ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ ุจุฏูุงู ูู ุฐูู.")
            
        result = client.models.generate_images(
            model=IMAGE_GENERATION_MODEL,
            prompt=full_prompt,
            config=dict(
                number_of_images=1,
                output_mime_type="image/jpeg",
                aspect_ratio="16:9"
            )
        )
        
        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "ูู ูุชููู ุงููููุฐุฌ ูู ุชูููุฏ ุตูุฑุฉ ุจูุงุกู ุนูู ุงููุตู."

    except Exception as e:
        if "API_KEY_INVALID" in str(e):
            return None, "ุฎุทุฃ: ููุชุงุญ Gemini API ุบูุฑ ุตุงูุญ ุฃู ุบูุฑ ูููุฃ ูุฎุฏูุฉ Imagen."
        return None, f"ุฎุทุฃ ูู ุชูููุฏ ุงูุตูุฑุฉ: {e}"


# ---------------------------------
# 4. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู (RAG+Vision)", layout="centered")
st.title("๐๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุจุตุฑู (RAG+Vision)")
st.caption("ูุญูู ูููุงุชู ูุตูุฑู ุงููุฑููุนุฉ ููุฅุฌุงุจุฉ.")

query_engine = setup_rag_engine()

def handle_image_generation(content, is_animation=False):
    # ูุณุชุฎุฏู ุฌุฒุก ูู ุงูุฅุฌุงุจุฉ ูุชูููุฏ ูุทุงูุจุฉ ููุตูุฑุฉ
    image_prompt = content[:200]
    
    image_bytes, error = generate_image(image_prompt, is_animation=is_animation)

    if image_bytes:
        st.image(image_bytes, caption=f"ุตูุฑุฉ ุชูุถูุญูุฉ ุชู ุชูููุฏูุง ูู: {image_prompt}...")
    else:
        st.error(f"ูุดู ุงูุชูููุฏ: {error}")


if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ุนุฑุถ ุงูุฑุณุงุฆู ุงูุณุงุจูุฉ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ุฅุถุงูุฉ ุฃุฒุฑุงุฑ ุงูุชูููุฏ ุจุนุฏ ูู ุฑุฏ ูู ุงููุณุงุนุฏ
            if message["role"] == "assistant":
                col1, col2 = st.columns(2)
                
                # ุงูุฒุฑ 1: ุชูููุฏ ุตูุฑุฉ ุชูุถูุญูุฉ (Graphic Design)
                with col1:
                    if st.button("๐ผ๏ธ ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                # ุงูุฒุฑ 2: ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ (ูุจุฏูู ููููุฏูู)
                with col2:
                    if st.button("๐ฌ ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ/ููุฏูู", key=f"gif_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=True)


    # >>> ููุทูุฉ ุชุญููู ุงูุตูุฑุฉ ูุงูุณุคุงู
    uploaded_file = st.file_uploader("๐ผ๏ธ ุงุฑูุน ุตูุฑุฉ ุทุจูุฉ ููุณุคุงู ุนููุง (ุงุฎุชูุงุฑู)", type=["png", "jpg", "jpeg"])

    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงูุ ูููููู ุฅุฑูุงู ุตูุฑุฉ..."):
        
        user_message = {"role": "user", "content": prompt}
        
        text_and_image_input = prompt
        image_to_query = None

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ุงูุตูุฑุฉ ุงููุฑููุนุฉ", width=200)
            
            # ุชุฌููุฒ ูุงุฆู ุงูุตูุฑุฉ ููุชู ุชูุฑูุฑู ุฅูู ูุญุฑู ุงูุงุณุชุนูุงู
            image_to_query = [image] 

            # ุชุนุฏูู ูุต ุงููุทุงูุจุฉ ููุชุถูู ุงูุชุนูููุงุช ุงูุฎุงุตุฉ ุจุงูุตูุฑุฉ
            text_and_image_input = f"ุญูู ุงูุตูุฑุฉ ุงููุฑููุนุฉ ูุนุชูุฏุงู ุนูู ูุฑุงุฌุนูุ ุซู ุฃุฌุจ ุนู ุงูุณุคุงู: {prompt}"

        st.session_state.messages.append(user_message)
        with st.chat_message("user"):
            st.markdown(text_and_image_input)

        with st.chat_message("assistant"):
            # ุงุณุชุฏุนุงุก ูุญุฑู ุงูุงุณุชุนูุงู ูุชูุฑูุฑ ุงูุตูุฑุฉ ุงููุฑููุนุฉ (ุฅู ูุฌุฏุช)
            response = query_engine.query(text_and_image_input, images=image_to_query) 
            
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})
    "ูุฌุจ ุนููู ุชุญููู ุงููุต ูุงูุตูุฑุฉ ุงููุฑููุฉ (ุฅู ูุฌุฏุช) ูุงุณุชุฎุฏุงููุง ูุน ุงููุฑุงุฌุน ุงููุณุชุฑุฌุนุฉ ููุฅุฌุงุจุฉ. "
    "ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉุ ูุน ุงูุญูุงุธ ุนูู ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุงูุฃุณุงุณูุฉ ุจุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ. "
    "ุนูุฏ ุทูุจ ุงูุฌุฏุงูู ุฃู ุงูููุงุฑูุงุช ุฃู ุงูุดุฑูุญุงุช ุงููุนูุฏุฉุ ูุฌุจ ุฃู ุชููุธููู ุงูุฅุฌุงุจุฉ ูู ุดูู ูุต ูููููู (Markdown) ูุงุถุญ ูููุฌุฒ."
# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ ุงููุชุนุฏุฏ ุงูุฃููุงุท
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets.")
        return None

    try:
        # LLM Multi-modal ููุฑุงุกุฉ ูููู ุงููุตูุต ูุงูุตูุฑ ูู ุงูููุฑุณ
        llm_multi = GeminiMultiModal(model="gemini-2.5-flash")
        # LLM ุงููุตู ููุญุฑู ุงูุงุณุชุนูุงู ุงูููุงุฆู
        llm_text = Gemini(model="gemini-2.5-flash")
        
    except Exception as e:
        st.error(f"โ ูุดู ุชููุฆุฉ ูููุฐุฌ Gemini: {e}")
        return None

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm_text)
        
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท (ุชุฃูุฏ ูู ูุฌูุฏ ุตูุฑ JPG/PNG ููููุงุช PDF)...")
        
        try:
            # ุงูุขู ุชูุฑุฃ ุงููุตูุต ูู PDF ูุงูุตูุฑ ูู JPG/PNG
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf", ".jpg", ".png"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ (ูุตู ูุจุตุฑู). ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm_multi, # ุงุณุชุฎุฏุงู ูููุฐุฌ ุงูุฃููุงุท ุงููุชุนุฏุฏุฉ ููููุฑุณุฉ
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุชุนุฏุฏุฉ ุงูุฃููุงุท ูุญูุธูุง ุจูุฌุงุญ!")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    query_engine = index.as_query_engine(
        llm=llm_text,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ุฏูุงู ุชูููุฏ ุงููุณุงุฆุท
# ---------------------------------

@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """
    ุชุณุชุฎุฏู ูููุฐุฌ Imagen ูุฅูุดุงุก ุตูุฑุฉ ุซุงุจุชุฉ (ุฌุฑุงููู) ุจูุงุกู ุนูู ุงููุตู.
    """
    client = get_gemini_client()
    
    # ุชุญุณูู ุงููุทุงูุจุฉ ูุฅูุดุงุก ุตูุฑุฉ ุทุจูุฉ ุงุญุชุฑุงููุฉ
    full_prompt = (
        f"Detailed medical diagram, high-quality colorful graphic design, "
        f"featuring arrows and explanatory labels showing the {prompt}"
    )
    
    st.info(f"๐จ ุฌุงุฑู ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู ูู: {prompt}")

    try:
        if is_animation:
            st.warning("ุชูููุฏ ุงูููุฏูู/ุงูุตูุฑ ุงููุชุญุฑูุฉ ูุนูุฏ ูู Streamlit. ุณูุชู ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ ุจุฏูุงู ูู ุฐูู.")
            
        result = client.models.generate_images(
            model=IMAGE_GENERATION_MODEL,
            prompt=full_prompt,
            config=dict(
                number_of_images=1,
                output_mime_type="image/jpeg",
                aspect_ratio="16:9"
            )
        )
        
        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "ูู ูุชููู ุงููููุฐุฌ ูู ุชูููุฏ ุตูุฑุฉ ุจูุงุกู ุนูู ุงููุตู."

    except Exception as e:
        if "API_KEY_INVALID" in str(e):
            return None, "ุฎุทุฃ: ููุชุงุญ Gemini API ุบูุฑ ุตุงูุญ ุฃู ุบูุฑ ูููุฃ ูุฎุฏูุฉ Imagen."
        return None, f"ุฎุทุฃ ูู ุชูููุฏ ุงูุตูุฑุฉ: {e}"


# ---------------------------------
# 4. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู (RAG+Vision)", layout="centered")
st.title("๐๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุจุตุฑู (RAG+Vision)")
st.caption("ูุญูู ูููุงุชู ูุตูุฑู ุงููุฑููุนุฉ ููุฅุฌุงุจุฉ.")

query_engine = setup_rag_engine()

def handle_image_generation(content, is_animation=False):
    # ูุณุชุฎุฏู ุฌุฒุก ูู ุงูุฅุฌุงุจุฉ ูุชูููุฏ ูุทุงูุจุฉ ููุตูุฑุฉ
    image_prompt = content[:200]
    
    image_bytes, error = generate_image(image_prompt, is_animation=is_animation)

    if image_bytes:
        st.image(image_bytes, caption=f"ุตูุฑุฉ ุชูุถูุญูุฉ ุชู ุชูููุฏูุง ูู: {image_prompt}...")
    else:
        st.error(f"ูุดู ุงูุชูููุฏ: {error}")


if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ุนุฑุถ ุงูุฑุณุงุฆู ุงูุณุงุจูุฉ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ุฅุถุงูุฉ ุฃุฒุฑุงุฑ ุงูุชูููุฏ ุจุนุฏ ูู ุฑุฏ ูู ุงููุณุงุนุฏ
            if message["role"] == "assistant":
                col1, col2 = st.columns(2)
                
                # ุงูุฒุฑ 1: ุชูููุฏ ุตูุฑุฉ ุชูุถูุญูุฉ (Graphic Design)
                with col1:
                    if st.button("๐ผ๏ธ ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                # ุงูุฒุฑ 2: ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ (ูุจุฏูู ููููุฏูู)
                with col2:
                    if st.button("๐ฌ ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ/ููุฏูู", key=f"gif_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=True)


    # >>> ููุทูุฉ ุชุญููู ุงูุตูุฑุฉ ูุงูุณุคุงู
    uploaded_file = st.file_uploader("๐ผ๏ธ ุงุฑูุน ุตูุฑุฉ ุทุจูุฉ ููุณุคุงู ุนููุง (ุงุฎุชูุงุฑู)", type=["png", "jpg", "jpeg"])

    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงูุ ูููููู ุฅุฑูุงู ุตูุฑุฉ..."):
        
        user_message = {"role": "user", "content": prompt}
        
        text_and_image_input = prompt
        image_to_query = None

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ุงูุตูุฑุฉ ุงููุฑููุนุฉ", width=200)
            
            # ุชุฌููุฒ ูุงุฆู ุงูุตูุฑุฉ ููุชู ุชูุฑูุฑู ุฅูู ูุญุฑู ุงูุงุณุชุนูุงู
            image_to_query = [image] 

            # ุชุนุฏูู ูุต ุงููุทุงูุจุฉ ููุชุถูู ุงูุชุนูููุงุช ุงูุฎุงุตุฉ ุจุงูุตูุฑุฉ
            text_and_image_input = f"ุญูู ุงูุตูุฑุฉ ุงููุฑููุนุฉ ูุนุชูุฏุงู ุนูู ูุฑุงุฌุนูุ ุซู ุฃุฌุจ ุนู ุงูุณุคุงู: {prompt}"

        st.session_state.messages.append(user_message)
        with st.chat_message("user"):
            st.markdown(text_and_image_input)

        with st.chat_message("assistant"):
            # ุงุณุชุฏุนุงุก ูุญุฑู ุงูุงุณุชุนูุงู ูุชูุฑูุฑ ุงูุตูุฑุฉ ุงููุฑููุนุฉ (ุฅู ูุฌุฏุช)
            response = query_engine.query(text_and_image_input, images=image_to_query) 
            
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})
INDEX_STORAGE_DIR = "storage"
PDF_DIR = "./" 
IMAGE_GENERATION_MODEL = 'imagen-3.0-generate-002' # ูููุฐุฌ ุชูููุฏ ุงูุตูุฑ

MEDICAL_URLS = [
    "https://pubmed.ncbi.nlm.nih.gov/", 
    "https://www.who.int/ar", 
    "https://www.cdc.gov/",
    "https://www.mayoclinic.org/",
    "https://www.medscape.com/",
    "https://www.hopkinsmedicine.org/",
]

SYSTEM_PROMPT = (
    "ุฃูุช ูุณุงุนุฏ ุทุจู ุฐูู ูุชุฎุตุต ูู ุงูุฅุฌุงุจุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุทูุงุจ ุงูุทุจ. "
    "ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉุ ูุน ุงูุญูุงุธ ุนูู ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุงูุฃุณุงุณูุฉ (ุงูุฃูุฑุงุถุ ุงูุฃุฏููุฉุ ุงููุตุทูุญุงุช ุงูุชุดุฑูุญูุฉ) ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ ุฏุงุฎู ุงูุฃููุงุณ. ูุฌุจ ุฃู ุชูุฏู ุฅุฌุงุจุงุชู ูู ุดูู ููุธูุ ูุชุณุชุฎุฏู ุงูุฌุฏุงูู ูุงูุนูุงุตุฑ ุงููุฑููุฉ ุนูุฏ ุทูุจ ุงูููุงุฑูุงุช. ููุง ููููู ุฅูุดุงุก ุฃุณุฆูุฉ ุชุฏุฑูุจูุฉ ูุน ุชูุณูุฑ ุงูุฅุฌุงุจุฉ ุจูุงุกู ุนูู ุงููุญุชูู ุงููุณุชุฑุฌุน. "
    "ุงูุฅุฌุงุจุงุช ูุฌุจ ุฃู ุชููู ุฏูููุฉ ููุงุถุญุฉ ููุจููุฉ ุจุงููุงูู ุนูู ุงููุฑุงุฌุน ุงูุทุจูุฉ ุงููุชููุฑุฉ ูุฏูู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุฑููุฉ. ุฅุฐุง ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉุ ุงุฐูุฑ ุฐูู ุจูุถูุญ."
)

# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets ุฃู ุงูููุฏ.")
        return None

    try:
        llm = Gemini(model="gemini-2.5-flash")
    except Exception as e:
        st.error(f"โ ูุดู ุชููุฆุฉ ูููุฐุฌ Gemini: {e}")
        return None

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm)
        
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุฃูู ูุฑุฉ (ูุฏ ูุณุชุบุฑู ุจุถุน ุฏูุงุฆู)...")
        
        try:
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ. ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(documents, llm=llm)
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุญูุธูุง ุจูุฌุงุญ!")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    query_engine = index.as_query_engine(
        llm=llm,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ุฏูุงู ุชูููุฏ ุงููุณุงุฆุท (ุงูุตูุฑ/ุงูุฌุฑุงููู/ุงูุตูุฑ ุงููุชุญุฑูุฉ)
# ---------------------------------

@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """
    ุชุณุชุฎุฏู ูููุฐุฌ Imagen ูุฅูุดุงุก ุตูุฑุฉ ุซุงุจุชุฉ ุฃู ูุชุญุฑูุฉ ุจูุงุกู ุนูู ุงููุตู.
    """
    client = get_gemini_client()
    
    # ุชุญุณูู ุงููุทุงูุจุฉ ูุฅูุดุงุก ุตูุฑุฉ ุทุจูุฉ ุงุญุชุฑุงููุฉ
    full_prompt = (
        f"Detailed medical diagram, high-quality colorful graphic design, "
        f"featuring arrows and explanatory labels showing the {prompt}"
    ) # <--- ุชู ุชุทุจูู ุชุญุณูู "ุงูุฃุณูู ูุงูุดุฑูุญุงุช" ููุง!
    
    st.info(f"๐จ ุฌุงุฑู ุชูููุฏ {'ุตูุฑุฉ ูุชุญุฑูุฉ (GIF)' if is_animation else 'ุตูุฑุฉ ุชูุถูุญูุฉ'} ูู: {prompt}")

    try:
        if is_animation:
            st.warning("ุชูููุฏ ุงูููุฏูู/ุงูุตูุฑ ุงููุชุญุฑูุฉ ูุนูุฏ ูู Streamlit. ุณูุชู ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ ุจุฏูุงู ูู ุฐูู.")
            is_animation = False

        if not is_animation:
            result = client.models.generate_images(
                model=IMAGE_GENERATION_MODEL,
                prompt=full_prompt,
                config=dict(
                    number_of_images=1,
                    output_mime_type="image/jpeg",
                    aspect_ratio="16:9"
                )
            )
        
        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "ูู ูุชููู ุงููููุฐุฌ ูู ุชูููุฏ ุตูุฑุฉ ุจูุงุกู ุนูู ุงููุตู."

    except Exception as e:
        if "API_KEY_INVALID" in str(e):
            return None, "ุฎุทุฃ: ููุชุงุญ Gemini API ุบูุฑ ุตุงูุญ ุฃู ุบูุฑ ูููุฃ ูุฎุฏูุฉ Imagen."
        return None, f"ุฎุทุฃ ูู ุชูููุฏ ุงูุตูุฑุฉ: {e}"


# ---------------------------------
# 4. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (RAG+Vision)", layout="centered")
st.title("๐จโโ๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (Rุงุฆุฏ)")
st.caption("ูุนุชูุฏ ุนูู ูุฑุงุฌุนู ุงูุทุจูุฉ ูุฎุฏูุฉ ุชูููุฏ ุงูุตูุฑ (Imagen)")

query_engine = setup_rag_engine()

def handle_image_generation(content, is_animation=False):
    # ูุณุชุฎุฏู ุฌุฒุก ูู ุงูุฅุฌุงุจุฉ ูุชูููุฏ ูุทุงูุจุฉ ููุตูุฑุฉ
    image_prompt = content[:200]
    
    if is_animation:
        image_bytes, error = generate_image(image_prompt, is_animation=True)
    else:
        image_bytes, error = generate_image(image_prompt, is_animation=False)

    if image_bytes:
        st.image(image_bytes, caption=f"ุตูุฑุฉ ุชูุถูุญูุฉ ุชู ุชูููุฏูุง ูู: {image_prompt}...")
    else:
        st.error(f"ูุดู ุงูุชูููุฏ: {error}")


if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ุฅุถุงูุฉ ุฃุฒุฑุงุฑ ุงูุชูููุฏ ุจุนุฏ ูู ุฑุฏ ูู ุงููุณุงุนุฏ (ูุชุญููู ุงูุงุณุชุฑุฌุงุน ุงูุจุตุฑู)
            if message["role"] == "assistant":
                col1, col2 = st.columns(2)
                
                # ุงูุฒุฑ 1: ุชูููุฏ ุตูุฑุฉ ุชูุถูุญูุฉ (Graphic Design)
                with col1:
                    if st.button("๐ผ๏ธ ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                # ุงูุฒุฑ 2: ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ (ูุจุฏูู ููููุฏูู)
                with col2:
                    if st.button("๐ฌ ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ/ููุฏูู", key=f"gif_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=True)


    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงู..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response = query_engine.query(prompt)
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})
    "ุงูุฅุฌุงุจุงุช ูุฌุจ ุฃู ุชููู ุฏูููุฉ ููุงุถุญุฉ ููุจููุฉ ุจุงููุงูู ุนูู ุงููุฑุงุฌุน ุงูุทุจูุฉ ุงููุชููุฑุฉ ูุฏูู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุฑููุฉ. ุฅุฐุง ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉุ ุงุฐูุฑ ุฐูู ุจูุถูุญ."
# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets ุฃู ุงูููุฏ.")
        return None

    try:
        # ุชููุฆุฉ ุงูุนููู ุงููุดุชุฑู ูู Gemini (ูููููุฐุฌ ุงููุบูู)
        llm = Gemini(model="gemini-2.5-flash")
    except Exception as e:
        st.error(f"โ ูุดู ุชููุฆุฉ ูููุฐุฌ Gemini: {e}")
        return None

    # ุชุญููู ุงูููุฑุณ ุฅุฐุง ูุงู ููุฌูุฏุงู
    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm)
        
    # ุจูุงุก ุงูููุฑุณ ุฅุฐุง ูู ููู ููุฌูุฏุงู
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุฃูู ูุฑุฉ (ูุฏ ูุณุชุบุฑู ุจุถุน ุฏูุงุฆู)...")
        
        try:
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ. ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(documents, llm=llm)
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุญูุธูุง ุจูุฌุงุญ!")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    # ุฅูุดุงุก ูุญุฑู ุงูุงุณุชุนูุงู
    query_engine = index.as_query_engine(
        llm=llm,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ุฏูุงู ุชูููุฏ ุงููุณุงุฆุท (ุงูุตูุฑ/ุงูุฌุฑุงููู/ุงูุตูุฑ ุงููุชุญุฑูุฉ)
# ---------------------------------

# ุชููุฆุฉ ุนููู Gemini ูููุงู ุชูููุฏ ุงูุตูุฑ
@st.cache_resource
def get_gemini_client():
    return genai.Client()

def generate_image(prompt: str, is_animation=False):
    """
    ุชุณุชุฎุฏู ูููุฐุฌ Imagen ูุฅูุดุงุก ุตูุฑุฉ ุซุงุจุชุฉ ุฃู ูุชุญุฑูุฉ ุจูุงุกู ุนูู ุงููุตู.
    """
    client = get_gemini_client()
    
    # ุชุญุณูู ุงููุทุงูุจุฉ ูุฅูุดุงุก ุตูุฑุฉ ุทุจูุฉ ุงุญุชุฑุงููุฉ
    full_prompt = f"Medical illustration, accurate, detailed, and colorful graphic design of: {prompt}"
    
    st.info(f"๐จ ุฌุงุฑู ุชูููุฏ {'ุตูุฑุฉ ูุชุญุฑูุฉ (GIF)' if is_animation else 'ุตูุฑุฉ ุชูุถูุญูุฉ'} ูู: {prompt}")

    try:
        # ุฅุฐุง ูุงูุช ุตูุฑุฉ ูุชุญุฑูุฉ (GIF)ุ ูุณุชุฎุฏู ููุฒุฉ ุงูุฅุฎุฑุงุฌ ูููุฏูู/GIF
        if is_animation:
            result = client.models.generate_images(
                model=IMAGE_GENERATION_MODEL,
                prompt=full_prompt,
                config=dict(
                    number_of_images=1,
                    output_mime_type="video/mp4", # ูููุถู ููุฏูู ูุตูุฑ
                    aspect_ratio="1:1"
                )
            )
            # ุจูุง ุฃู Streamlit ูุง ูุนุฑุถ ุงูููุฏูู/GIF ุงููุดูุฑ ูุจุงุดุฑุฉ ูู ุจุงูุชุณ Geminiุ
            # ูุญุชุงุฌ ุฅูู ุทุฑููุฉ ูุฎุชููุฉ ููุนุฑุถ (ูุฏ ุชุชุทูุจ ุญูุธ ุงูููู ูู Replit ุฃููุงูุ ููููุง ุณูุชุฌุงูุฒูุง ุญุงููุงู ุจุนุฑุถ ุงูุตูุฑุฉ ุงูุซุงุจุชุฉ ุงูุฃุณูู).
            # ุณููุชูู ููุง ุจุนุฑุถ ุงูุตูุฑุฉ ุงูุซุงุจุชุฉ ูุจุฏูู ูุถููู.
            st.warning("ุชูููุฏ ุงูููุฏูู/ุงูุตูุฑ ุงููุชุญุฑูุฉ ูุนูุฏ ูู Streamlit. ุณูุชู ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ ุจุฏูุงู ูู ุฐูู.")
            is_animation = False

        # ุชูููุฏ ุตูุฑุฉ ุซุงุจุชุฉ
        if not is_animation:
            result = client.models.generate_images(
                model=IMAGE_GENERATION_MODEL,
                prompt=full_prompt,
                config=dict(
                    number_of_images=1,
                    output_mime_type="image/jpeg",
                    aspect_ratio="16:9"
                )
            )
        
        if result.generated_images:
            image_data = result.generated_images[0].image.image_bytes
            return image_data, None
        else:
            return None, "ูู ูุชููู ุงููููุฐุฌ ูู ุชูููุฏ ุตูุฑุฉ ุจูุงุกู ุนูู ุงููุตู."

    except Exception as e:
        # ุชุญูู ููุง ุฅุฐุง ูุงู ุงูุณุจุจ ูู ุนุฏู ุฅุนุฏุงุฏ ููุชุงุญ API
        if "API_KEY_INVALID" in str(e):
            return None, "ุฎุทุฃ: ููุชุงุญ Gemini API ุบูุฑ ุตุงูุญ ุฃู ุบูุฑ ูููุฃ ูุฎุฏูุฉ Imagen."
        return None, f"ุฎุทุฃ ูู ุชูููุฏ ุงูุตูุฑุฉ: {e}"


# ---------------------------------
# 4. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (RAG+Vision)", layout="centered")
st.title("๐จโโ๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (Rุงุฆุฏ)")
st.caption("ูุนุชูุฏ ุนูู ูุฑุงุฌุนู ุงูุทุจูุฉ ูุฎุฏูุฉ ุชูููุฏ ุงูุตูุฑ (Imagen)")

query_engine = setup_rag_engine()

# ูุธููุฉ ูุฎุตุตุฉ ููุงุณุชุฌุงุจุฉ ุนูุฏ ุงูุถุบุท ุนูู ุฒุฑ ุชูููุฏ ุงูุตูุฑุฉ
def handle_image_generation(content, is_animation=False):
    # ูุณุชุฎุฏู ุฌุฒุก ูู ุงูุฅุฌุงุจุฉ ูุชูููุฏ ูุทุงูุจุฉ ููุตูุฑุฉ
    image_prompt = content[:200]
    
    # ุชุญุฏูุฏ ููุน ุงูุชูููุฏ
    if is_animation:
        image_bytes, error = generate_image(image_prompt, is_animation=True)
    else:
        image_bytes, error = generate_image(image_prompt, is_animation=False)

    if image_bytes:
        st.image(image_bytes, caption=f"ุตูุฑุฉ ุชูุถูุญูุฉ ุชู ุชูููุฏูุง ูู: {image_prompt}...")
    else:
        st.error(f"ูุดู ุงูุชูููุฏ: {error}")


if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ุฅุถุงูุฉ ุฃุฒุฑุงุฑ ุงูุชูููุฏ ุจุนุฏ ูู ุฑุฏ ูู ุงููุณุงุนุฏ (ูุชุญููู ุงูุงุณุชุฑุฌุงุน ุงูุจุตุฑู)
            if message["role"] == "assistant":
                col1, col2 = st.columns(2)
                
                # ุงูุฒุฑ 1: ุชูููุฏ ุตูุฑุฉ ุชูุถูุญูุฉ (Graphic Design)
                with col1:
                    if st.button("๐ผ๏ธ ุชูููุฏ ุฌุฑุงููู ุชูุถูุญู", key=f"img_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=False)

                # ุงูุฒุฑ 2: ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ (ูุจุฏูู ููููุฏูู)
                with col2:
                    if st.button("๐ฌ ุชูููุฏ ุตูุฑุฉ ูุชุญุฑูุฉ/ููุฏูู", key=f"gif_{hash(message['content'])}"):
                        handle_image_generation(message['content'], is_animation=True)


# ูุฐุง ุฌุฒุก ูู ุงูููุฏ ุงูุฐู ููููู ุชุนุฏููู (ูู ุฏุงูุฉ handle_image_generation)

# ุชุญุณูู ุงููุทุงูุจุฉ ูุชูููุฏ ุตูุฑุฉ ุฐุงุช ุฃุณูู ูุดุฑูุญุงุช
full_prompt = (
    f"Detailed medical diagram, high-quality colorful graphic design, "
    f"featuring arrows and explanatory labels showing the {image_prompt}"
)

    
if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงู..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response = query_engine.query(prompt)
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})
    
# **ููู:** ุงูู SYSTEM PROMPT ุงููุญุฏุซ ุจูุงุกู ุนูู ุทูุจู
SYSTEM_PROMPT = (
    "ุฃูุช ูุณุงุนุฏ ุทุจู ุฐูู ูุชุฎุตุต ูู ุงูุฅุฌุงุจุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุทูุงุจ ุงูุทุจ. "
    "ูุฌุจ ุฃู ุชููู ุฅุฌุงุจุงุชู ุฏูููุฉ ููุงุถุญุฉ ููุจููุฉ ุจุงููุงูู ุนูู ุงููุฑุงุฌุน ุงูุทุจูุฉ "
    "ุงููุชููุฑุฉ ูุฏูู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุฑููุฉ. ุฅุฐุง ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉุ ุงุฐูุฑ ุฐูู ุจูุถูุญ. "
    "ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉุ ูุน ุงูุญูุงุธ ุนูู **ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุงูุฃุณุงุณูุฉ (ุงูุฃูุฑุงุถุ ุงูุฃุฏููุฉุ ุงููุตุทูุญุงุช ุงูุชุดุฑูุญูุฉ)** ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ ุฏุงุฎู ุงูุฃููุงุณ. ูุฌุจ ุฃู ุชูุฏู ุฅุฌุงุจุงุชู ูู ุดูู ููุธูุ ูุชุณุชุฎุฏู ุงูุฌุฏุงูู ูุงูุนูุงุตุฑ ุงููุฑููุฉ ุนูุฏ ุทูุจ ุงูููุงุฑูุงุช. ููุง ููููู ุฅูุดุงุก ุฃุณุฆูุฉ ุชุฏุฑูุจูุฉ ูุน ุชูุณูุฑ ุงูุฅุฌุงุจุฉ ุจูุงุกู ุนูู ุงููุญุชูู ุงููุณุชุฑุฌุน."
)


# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ (@st.cache_resource)
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    # ุงูุชุญูู ูู ููุชุงุญ API
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets ุฃู ุงูููุฏ.")
        return None

    llm = Gemini(model="gemini-2.5-flash")

    # ุชุญููู ุงูููุฑุณ ุฅุฐุง ูุงู ููุฌูุฏุงู
    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm)
        
    # ุจูุงุก ุงูููุฑุณ ุฅุฐุง ูู ููู ููุฌูุฏุงู
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุฃูู ูุฑุฉ (ูุฏ ูุณุชุบุฑู ุจุถุน ุฏูุงุฆู)...")
        
        try:
            # ูุฑุงุกุฉ ูููุงุช PDF
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf"]).load_data()
            # ูุฑุงุกุฉ ุงูููุงูุน ุงูุฅููุชุฑูููุฉ
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ. ุฌุงุฑู ุงูููุฑุณุฉ...")

            # ุจูุงุก ุงูููุฑุณ ูุญูุธู
            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm,
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุญูุธูุง ุจูุฌุงุญ! ุงูุจุฑูุงูุฌ ุฌุงูุฒ.")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    # ุฅูุดุงุก ูุญุฑู ุงูุงุณุชุนูุงู
    query_engine = index.as_query_engine(
        llm=llm,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู ุงูุฑุฆูุณู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (RAG)", layout="centered")
st.title("๐จโโ๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต")
st.caption("ูุนุชูุฏ ุนูู ูุฑุงุฌุนู ุงูุทุจูุฉ (PDFs + URLs) ุจุงุณุชุฎุฏุงู Gemini 2.5 Flash")

query_engine = setup_rag_engine()

if query_engine:
    # ุชููุฆุฉ ุณุฌู ุงูุฏุฑุฏุดุฉ
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ุนุฑุถ ุงูุฑุณุงุฆู ุงูุณุงุจูุฉ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ูุฑุจุน ุฅุฏุฎุงู ุงููุณุชุฎุฏู
    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงู..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ุงุณุชุฏุนุงุก ูุญุฑู ุงูุงุณุชุนูุงู ูุชูููุฏ ุงูุฑุฏ
        with st.chat_message("assistant"):
            response = query_engine.query(prompt)
            st.write_stream(response.response_gen)
            # ุชุฎุฒูู ุงูุฑุฏ ุงููุงูู ูู ุงูุฌูุณุฉ
            st.session_state.messages.append({"role": "assistant", "content": response.response})
            "https://www.medscape.com/",
    
    # Johns Hopkins Medicine (ุทุจ ุฌููุฒ ููุจููุฒ)
    "https://www.hopkinsmedicine.org/",
    
    # ููุงุญุธุฉ: ููููู ุฅุถุงูุฉ ุฃู ุฑุงุจุท ุขุฎุฑ ุชุฑูุฏ ุฃู ูุณุชูู ููู ุงููููุฐุฌ ูุนูููุงุชู ููุง
    # "https://your-favorite-university-medical-journal.com/article", 

SYSTEM_PROMPT = (
    "ุฃูุช ูุณุงุนุฏ ุทุจู ุฐูู ูุชุฎุตุต ูู ุงูุฅุฌุงุจุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุทูุงุจ ุงูุทุจ. "
    "ูุฌุจ ุฃู ุชููู ุฅุฌุงุจุงุชู ุฏูููุฉ ููุงุถุญุฉ ููุจููุฉ ุจุงููุงูู ุนูู ุงููุฑุงุฌุน ุงูุทุจูุฉ "
    "ุงููุชููุฑุฉ ูุฏูู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงููุฑููุฉ. ุฅุฐุง ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉุ ุงุฐูุฑ ุฐูู ุจูุถูุญ. "
    "ุงูุฑุฏูุฏ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉ ูุน ุฐูุฑ ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุจุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ ุญูุซูุง ูุฒู ุงูุฃูุฑ."
      "ุงูุฅุฌุงุจุฉ ูุฌุจ ุฃู ุชููู ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุงููุตุฑูู ุฃู ุงูุนุงููุฉ ุงููุตุฑูุฉ ุฃู  ุงูุงูุฌููุฒูู ุ ูุน ุงูุญูุงุธ ุนูู **ุงููุตุทูุญุงุช ุงูุทุจูุฉ ุงูุฃุณุงุณูุฉ (ุงูุฃูุฑุงุถุ ุงูุฃุฏููุฉุ ุงููุตุทูุญุงุช ุงูุชุดุฑูุญูุฉ)** ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ/ุงููุงุชูููุฉ ุฏุงุฎู ุงูุฃููุงุณ. ูุฌุจ ุฃู ุชูุฏู ุฅุฌุงุจุงุชู ูู ุดูู ููุธูุ ูุชุณุชุฎุฏู ุงูุฌุฏุงูู ูุงูุนูุงุตุฑ ุงููุฑููุฉ ุนูุฏ ุทูุจ ุงูููุงุฑูุงุช."
)

# ---------------------------------
# 2. ุจูุงุก/ุชุญููู ุงูููุฑุณ
# ---------------------------------

@st.cache_resource
def setup_rag_engine():
    
    # ุงูุชุญูู ูู ูุฌูุฏ ุงูููุชุงุญ ูุจู ุงูุจุฏุก
    if "GEMINI_API_KEY" not in os.environ and not Path(INDEX_STORAGE_DIR).exists():
        st.error("โ ุงูููุชุงุญ ุงูุณุฑู ูู Gemini ููููุฏ! ูุฑุฌู ุฅุถุงูุชู ูู Secrets ุฃู ุงูููุฏ.")
        return None

    llm = Gemini(model="gemini-2.5-flash")

    if Path(INDEX_STORAGE_DIR).exists():
        st.info("๐ ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงูููุฌูุฏุฉ ูุณุจููุง...")
        storage_context = StorageContext.from_defaults(persist_dir=INDEX_STORAGE_DIR)
        index = load_index_from_storage(storage_context, llm=llm)
        
    else:
        st.warning("โณ ุฌุงุฑู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุฃูู ูุฑุฉ (ุณูุนุชูุฏ ุนูู ููุฉ ุงุชุตุงูู ุจุงูุฅูุชุฑูุช)...")
        
        try:
            pdf_documents = SimpleDirectoryReader(input_dir=PDF_DIR, required_exts=[".pdf"]).load_data()
            url_documents = SimpleWebPageReader(input_urls=MEDICAL_URLS).load_data()
            documents = pdf_documents + url_documents
            st.info(f"ุชู ุชุญููู {len(documents)} ูุณุชูุฏ. ุฌุงุฑู ุงูููุฑุณุฉ...")

            index = VectorStoreIndex.from_documents(
                documents,
                llm=llm,
            )
            index.storage_context.persist(persist_dir=INDEX_STORAGE_DIR)
            st.success("โ ุชู ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ูุญูุธูุง ุจูุฌุงุญ! ุงูุจุฑูุงูุฌ ุฌุงูุฒ.")
            
        except Exception as e:
            st.error(f"โ ุฎุทุฃ ุญุฑุฌ ูู ุจูุงุก ุงูููุฑุณ: {e}")
            return None

    # ุฅูุดุงุก ูุญุฑู ุงูุงุณุชุนูุงู
    query_engine = index.as_query_engine(
        llm=llm,
        system_prompt=SYSTEM_PROMPT,
        streaming=True
    )
    return query_engine

# ---------------------------------
# 3. ูุงุฌูุฉ Streamlit (ุงูุชุทุจูู)
# ---------------------------------

st.set_page_config(page_title="ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต (RAG)", layout="centered")
st.title("๐จโโ๏ธ ูุณุงุนุฏู ุงูุทุจู ุงูุฎุงุต")
st.caption("ูุนุชูุฏ ุนูู ูุฑุงุฌุนู ุงูุทุจูุฉ (PDFs + URLs) ุจุงุณุชุฎุฏุงู Gemini 2.5 Flash")

query_engine = setup_rag_engine()

if query_engine:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ุงุทุฑุญ ุณุคุงูุงู ุทุจูุงู..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response = query_engine.query(prompt)
            st.write_stream(response.response_gen)
            st.session_state.messages.append({"role": "assistant", "content": response.response})     